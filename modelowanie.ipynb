{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9362a3c1",
   "metadata": {},
   "source": [
    "## CZĘŚĆ 3: MODELOWANIE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24e600",
   "metadata": {},
   "source": [
    "1. Wczytanie danych, obróbka danych zgodnie z feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b531c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import sklearn \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e03182bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie danych - dane do trenowania modelu\n",
    "development_unit_df = pd.read_csv(\".\\\\dane\\\\training_sample_team4.csv\")\n",
    "\n",
    "## Ramka danych walidacyjna dla zespołu budującego\n",
    "test = pd.read_csv(\".\\\\dane\\\\validation_sample_team4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eb93d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "standard = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aefaef",
   "metadata": {},
   "source": [
    "zgodnie z wskazówkami, outliery zostały zastąpione wartościami granicznymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6f6aee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_outliers(df):\n",
    "    columns_to_be_checked = ['r', 'u', 'i', 'z', 'g']\n",
    "    \n",
    "    df = df[df['u'] > 0]\n",
    "\n",
    "    for i in range(len(columns_to_be_checked)):\n",
    "        column = df[columns_to_be_checked[i]]\n",
    "        Q1 = column.quantile(0.25)\n",
    "        Q3 = column.quantile(0.75)\n",
    "\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers = (column < lower_bound) | (column > upper_bound)\n",
    "\n",
    "        outliers_count = outliers.sum()\n",
    "\n",
    "        outliers_percentage = outliers.mean() * 100\n",
    "        \n",
    "        # Zastąpienie outlierów wartościami równymi Q1 - 1.5 * IQR lub Q3 + 1.5 * IQR\n",
    "        df.loc[outliers, columns_to_be_checked[i]] = np.where(column[outliers] < lower_bound, lower_bound, upper_bound)\n",
    "\n",
    "        ##print(\"Ilość outlierów dla kolumny \", columns_to_be_checked[i], \": \", outliers_count)\n",
    "        ##print(\"Procentowy udział outlierów dla kolumny \", columns_to_be_checked[i], \": \", outliers_percentage)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6564a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = handle_outliers(development_unit_df)\n",
    "test = handle_outliers(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3eab00",
   "metadata": {},
   "source": [
    "dla przypomnienia:\n",
    "###### usunięto kolumny silnie skorelowane\n",
    "###### filtry w kolorze czerwieni zostały zsumowane i zawarte w jednej, nowej kolumnie (r + i + z)\n",
    "###### końcowo, do tworzenia modeli użyto kolumn związanych z filtrami oraz kolumnę 'redshift' - uznano, że wszystkie zmienne związane z id lub z położeniem obiektów (kąty alpha i delta) nie wpływają na efektywność modelu\n",
    "###### kolumny zostały zestandaryzowane i/lub znormalizowane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35d7eff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_data(df):\n",
    "    df = df.loc[:, df.columns != 'rerun_ID']\n",
    "    df = df.loc[:, df.columns != 'obj_ID']\n",
    "    df = df.loc[:, df.columns != 'plate']\n",
    "    \n",
    "    df['r+i+z'] = df[['r', 'i', 'z']].sum(axis=1)\n",
    "\n",
    "    # Normalizacja\n",
    "    columns_to_normalize = ['run_ID', 'cam_col', 'spec_obj_ID', 'MJD', 'alpha', 'fiber_ID']\n",
    "    df[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\n",
    "\n",
    "    # Standaryzacja\n",
    "    columns_to_standardize = ['delta', 'u', 'g', 'r', 'i', 'z', 'redshift', 'field_ID', 'r+i+z']\n",
    "    df[columns_to_standardize] = standard.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "    # Usuwanie kolumn\n",
    "    df = df.drop(['MJD'], axis = 1)\n",
    "    df = df.drop(['r', 'i', 'z'], axis = 1)\n",
    "\n",
    "    # Odrzucenie cech na podstawie interpretacji ich znaczenia\n",
    "    df = df.drop(['spec_obj_ID'], axis = 1) # numer obiektu\n",
    "    df = df.drop(['alpha'], axis = 1) # współrzędne astronomiczne\n",
    "    df = df.drop(['delta'], axis = 1) # współrzędne astronomiczne\n",
    "    df = df.drop(['field_ID'], axis = 1) # numer pola ze zdjęcia (fragment zdjęcia)\n",
    "    df = df.drop(['cam_col'], axis = 1) # numer kolumny ze zdjęcia (fragment zdjęcia)\n",
    "    df = df.drop(['run_ID'], axis = 1) # numer zdjęcia\n",
    "    df = df.drop(['fiber_ID'], axis = 1) # numer włókna, które skierowało światło na płaszczyznę ogniskową\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e9864d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = modify_data(development_unit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "533025a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>r+i+z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.678738</td>\n",
       "      <td>0.564729</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.408604</td>\n",
       "      <td>1.427677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.548889</td>\n",
       "      <td>-1.533804</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>-0.730359</td>\n",
       "      <td>-1.239177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.744904</td>\n",
       "      <td>-2.029105</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.790164</td>\n",
       "      <td>-2.116429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.006758</td>\n",
       "      <td>-1.066027</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>-0.677478</td>\n",
       "      <td>-0.936643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.228689</td>\n",
       "      <td>-1.217197</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>-0.705030</td>\n",
       "      <td>-0.941500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          u         g   class  redshift     r+i+z\n",
       "0  0.678738  0.564729     QSO  2.408604  1.427677\n",
       "1 -1.548889 -1.533804  GALAXY -0.730359 -1.239177\n",
       "2 -1.744904 -2.029105    STAR -0.790164 -2.116429\n",
       "3 -1.006758 -1.066027  GALAXY -0.677478 -0.936643\n",
       "4 -1.228689 -1.217197  GALAXY -0.705030 -0.941500"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41716ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = modify_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f1191141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>r+i+z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.695839</td>\n",
       "      <td>0.356947</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.206901</td>\n",
       "      <td>1.031172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.181778</td>\n",
       "      <td>0.253523</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>-0.706093</td>\n",
       "      <td>0.985689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.366130</td>\n",
       "      <td>0.220645</td>\n",
       "      <td>QSO</td>\n",
       "      <td>2.013251</td>\n",
       "      <td>0.860169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.756569</td>\n",
       "      <td>0.622013</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.786839</td>\n",
       "      <td>-0.020183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.764057</td>\n",
       "      <td>0.794126</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>-0.010139</td>\n",
       "      <td>0.314667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          u         g   class  redshift     r+i+z\n",
       "0  0.695839  0.356947     QSO  2.206901  1.031172\n",
       "1  0.181778  0.253523  GALAXY -0.706093  0.985689\n",
       "2 -0.366130  0.220645     QSO  2.013251  0.860169\n",
       "3  0.756569  0.622013    STAR -0.786839 -0.020183\n",
       "4  0.764057  0.794126  GALAXY -0.010139  0.314667"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bfccf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.copy()\n",
    "t = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7f754",
   "metadata": {},
   "source": [
    "### 2. Modelowanie bez strojenia hiperparametrów: \n",
    "#### Użyto 7 modeli klasyfikacyjnych, następnie na podstawie ich predykcyjności wybrano modele do dalszej obróbki"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847b5116",
   "metadata": {},
   "source": [
    "Model 1 - KNeighboursClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cf0fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.9615238095238096\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.97      0.96      0.97     12538\n",
      "         QSO       0.96      0.93      0.94      3973\n",
      "        STAR       0.93      0.99      0.96      4489\n",
      "\n",
      "    accuracy                           0.96     21000\n",
      "   macro avg       0.95      0.96      0.96     21000\n",
      "weighted avg       0.96      0.96      0.96     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[12059   166   313]\n",
      " [  281  3687     5]\n",
      " [   40     3  4446]]\n",
      "AUC dla klasy GALAXY: 0.9797728165653182\n",
      "Gini dla klasy GALAXY: 0.9595456331306365\n",
      " \n",
      "AUC dla klasy QSO: 0.978214195600062\n",
      "Gini dla klasy QSO: 0.9564283912001239\n",
      " \n",
      "AUC dla klasy STAR: 0.9939763724215583\n",
      "Gini dla klasy STAR: 0.9879527448431167\n",
      " \n",
      "Średni AUC: 0.9839877948623128\n",
      "Gini coefficient: 0.9679755897246256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def evaluate_knn_model(train_data, train_target, test_data, test_target):\n",
    "    # Inicjalizacja modelu KNN z domyślnymi parametrami\n",
    "    knn_model = KNeighborsClassifier()\n",
    "    \n",
    "    # Trenowanie modelu na danych treningowych\n",
    "    knn_model.fit(train_data, train_target)\n",
    "    \n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = knn_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = knn_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "##train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "#test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_knn_model(train_data, train_target, test_data, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9848e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95edace1",
   "metadata": {},
   "source": [
    "Model 2 - RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0356b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.9635714285714285\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.96      0.98      0.97     12538\n",
      "         QSO       0.95      0.93      0.94      3973\n",
      "        STAR       0.98      0.96      0.97      4489\n",
      "\n",
      "    accuracy                           0.96     21000\n",
      "   macro avg       0.96      0.95      0.96     21000\n",
      "weighted avg       0.96      0.96      0.96     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[12255   174   109]\n",
      " [  283  3689     1]\n",
      " [  198     0  4291]]\n",
      "AUC dla klasy GALAXY: 0.9892064121289668\n",
      "Gini dla klasy GALAXY: 0.9784128242579335\n",
      " \n",
      "AUC dla klasy QSO: 0.9883353338032839\n",
      "Gini dla klasy QSO: 0.9766706676065677\n",
      " \n",
      "AUC dla klasy STAR: 0.9975750655250132\n",
      "Gini dla klasy STAR: 0.9951501310500264\n",
      " \n",
      "Średni AUC: 0.991705603819088\n",
      "Gini coefficient: 0.983411207638176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_forest_model(train_data, train_target, test_data, test_target):\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Trenowanie modelu\n",
    "    rf_model.fit(train_data, train_target)\n",
    "\n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = rf_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = rf_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "#test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_forest_model(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f78718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62faea46",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60f5d9",
   "metadata": {},
   "source": [
    "xboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d8c5fcc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.9452857142857143\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96     12538\n",
      "           1       0.95      0.93      0.94      3973\n",
      "           2       0.97      0.92      0.95      4489\n",
      "\n",
      "   micro avg       0.95      0.96      0.95     21000\n",
      "   macro avg       0.96      0.94      0.95     21000\n",
      "weighted avg       0.95      0.96      0.95     21000\n",
      " samples avg       0.95      0.96      0.95     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "AUC dla klasy 0: 0.9880172783365371\n",
      "Gini dla klasy 0: 0.9760345566730741\n",
      " \n",
      "AUC dla klasy 1: 0.9918030499256958\n",
      "Gini dla klasy 1: 0.9836060998513916\n",
      " \n",
      "AUC dla klasy 2: 0.9965855809230592\n",
      "Gini dla klasy 2: 0.9931711618461183\n",
      " \n",
      "Średni AUC: 0.992135303061764\n",
      "Gini coefficient: 0.984270606123528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_xboost_model(train_data, train_target, test_data, test_target):\n",
    "\n",
    "    xgb_model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Trenowanie modelu XGBoost\n",
    "    xgb_model.fit(train_data, train_target)\n",
    "\n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = xgb_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    #print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = xgb_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_xboost_model(train_data, train_target_encoded, test_data, test_target_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea92d14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e55e3c73",
   "metadata": {},
   "source": [
    "Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b01f45b",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "774c700a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.9655714285714285\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.96      0.98      0.97     12538\n",
      "         QSO       0.96      0.91      0.94      3973\n",
      "        STAR       0.98      0.97      0.97      4489\n",
      "\n",
      "    accuracy                           0.97     21000\n",
      "   macro avg       0.97      0.96      0.96     21000\n",
      "weighted avg       0.97      0.97      0.97     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[12275   154   109]\n",
      " [  341  3631     1]\n",
      " [  118     0  4371]]\n",
      "AUC dla klasy GALAXY: 0.9888525363631973\n",
      "Gini dla klasy GALAXY: 0.9777050727263945\n",
      " \n",
      "AUC dla klasy QSO: 0.9912534571652245\n",
      "Gini dla klasy QSO: 0.982506914330449\n",
      " \n",
      "AUC dla klasy STAR: 0.9963079488553632\n",
      "Gini dla klasy STAR: 0.9926158977107264\n",
      " \n",
      "Średni AUC: 0.992137980794595\n",
      "Gini coefficient: 0.9842759615891901\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def evaluate_gradient_model(train_data, train_target, test_data, test_target):\n",
    "\n",
    "    gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Trenowanie modelu Gradient Boosting\n",
    "    gb_model.fit(train_data, train_target)\n",
    "\n",
    "\n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = gb_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = gb_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "#test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_gradient_model(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685bd2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9bfb78e",
   "metadata": {},
   "source": [
    "Model 5: Regresja logistyczna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88a9fa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.9533333333333334\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.96      0.96      0.96     12538\n",
      "         QSO       0.94      0.88      0.91      3973\n",
      "        STAR       0.94      1.00      0.97      4489\n",
      "\n",
      "    accuracy                           0.95     21000\n",
      "   macro avg       0.95      0.95      0.95     21000\n",
      "weighted avg       0.95      0.95      0.95     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[12053   205   280]\n",
      " [  490  3480     3]\n",
      " [    0     2  4487]]\n",
      "AUC dla klasy GALAXY: 0.9830697143458644\n",
      "Gini dla klasy GALAXY: 0.9661394286917289\n",
      " \n",
      "AUC dla klasy QSO: 0.9850534243513777\n",
      "Gini dla klasy QSO: 0.9701068487027553\n",
      " \n",
      "AUC dla klasy STAR: 0.9956065121615257\n",
      "Gini dla klasy STAR: 0.9912130243230515\n",
      " \n",
      "Średni AUC: 0.9879098836195892\n",
      "Gini coefficient: 0.9758197672391784\n"
     ]
    }
   ],
   "source": [
    "def evaluate_regression_model(train_data, train_target, test_data, test_target):\n",
    "\n",
    "    log_reg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    log_reg_model.fit(train_data, train_target)\n",
    "\n",
    "\n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = log_reg_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = log_reg_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "#test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_regression_model(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2255d01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33dcfd76",
   "metadata": {},
   "source": [
    "Model 6: Model Markova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0689a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.897952380952381\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     12538\n",
      "           1       0.79      0.92      0.85      3973\n",
      "           2       0.97      0.71      0.82      4489\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     21000\n",
      "   macro avg       0.89      0.86      0.87     21000\n",
      "weighted avg       0.91      0.90      0.90     21000\n",
      " samples avg       0.90      0.90      0.90     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "AUC dla klasy 0: 0.9175784179083061\n",
      "Gini dla klasy 0: 0.8351568358166122\n",
      " \n",
      "AUC dla klasy 1: 0.9293184891599078\n",
      "Gini dla klasy 1: 0.8586369783198156\n",
      " \n",
      "AUC dla klasy 2: 0.8522944511134757\n",
      "Gini dla klasy 2: 0.7045889022269514\n",
      " \n",
      "Średni AUC: 0.8997304527272298\n",
      "Gini coefficient: 0.7994609054544597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "def evaluate_markov_model(train_data, train_target, test_data, test_target):\n",
    "    \n",
    "    markov_model = ClassifierChain(base_estimator=DecisionTreeClassifier(), order='random', random_state=42)\n",
    "    markov_model.fit(train_data, train_target)\n",
    "\n",
    "\n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = markov_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    #print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = markov_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_markov_model(train_data, train_target_encoded, test_data, test_target_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaad680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad869696",
   "metadata": {},
   "source": [
    "Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0b38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Adaptacyjne drzewa decyzyjne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acc7e030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokładność całkowita (Accuracy): 0.9015238095238095\n",
      "\n",
      "Raport klasyfikacji:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.93      0.96      0.95     12538\n",
      "         QSO       0.77      0.92      0.84      3973\n",
      "        STAR       0.97      0.72      0.83      4489\n",
      "\n",
      "    accuracy                           0.90     21000\n",
      "   macro avg       0.89      0.87      0.87     21000\n",
      "weighted avg       0.91      0.90      0.90     21000\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[12045   397    96]\n",
      " [  325  3647     1]\n",
      " [  563   686  3240]]\n",
      "AUC dla klasy GALAXY: 0.9278699018279161\n",
      "Gini dla klasy GALAXY: 0.8557398036558321\n",
      " \n",
      "AUC dla klasy QSO: 0.9271706367779894\n",
      "Gini dla klasy QSO: 0.8543412735559788\n",
      " \n",
      "AUC dla klasy STAR: 0.8579447207333064\n",
      "Gini dla klasy STAR: 0.7158894414666128\n",
      " \n",
      "Średni AUC: 0.9043284197797373\n",
      "Gini coefficient: 0.8086568395594746\n"
     ]
    }
   ],
   "source": [
    "def evaluate_decisiontree_model(train_data, train_target, test_data, test_target):\n",
    "\n",
    "    \n",
    "    adtree_model = DecisionTreeClassifier()\n",
    "    adtree_model.fit(train_data, train_target)\n",
    "\n",
    "\n",
    "    # Predykcja klas dla danych testowych\n",
    "    test_predictions = adtree_model.predict(test_data)\n",
    "    \n",
    "    # Dokładność całkowita\n",
    "    accuracy = accuracy_score(test_target, test_predictions)\n",
    "    print(\"Dokładność całkowita (Accuracy):\", accuracy)\n",
    "    \n",
    "    # Raport klasyfikacji\n",
    "    print(\"\\nRaport klasyfikacji:\")\n",
    "    print(classification_report(test_target, test_predictions))\n",
    "    \n",
    "    # Macierz pomyłek\n",
    "    print(\"\\nConfusion matrix:\")\n",
    "    print(confusion_matrix(test_target, test_predictions))\n",
    "    \n",
    "    proba_predictions = adtree_model.predict_proba(test_data)\n",
    "    \n",
    "    # Konwersja etykiet klas na formę binarną dla każdej klasy\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(train_target)\n",
    "    test_target_bin = lb.transform(test_target)\n",
    "    \n",
    "    # Obliczenie AUC dla każdej klasy\n",
    "    auc_scores = []\n",
    "    for i in range(len(lb.classes_)):\n",
    "        auc_score = roc_auc_score(test_target_bin[:, i], proba_predictions[:, i])\n",
    "        auc_scores.append(auc_score)\n",
    "        print(f\"AUC dla klasy {lb.classes_[i]}: {auc_score}\")\n",
    "        print(f\"Gini dla klasy {lb.classes_[i]}: {2 * auc_score - 1}\")\n",
    "        print(\" \")\n",
    "    \n",
    "    # Średni AUC\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    print(\"Średni AUC:\", mean_auc)\n",
    "    \n",
    "    gini_coefficient = 2 * mean_auc - 1\n",
    "    print(\"Gini coefficient:\", gini_coefficient)\n",
    "\n",
    "# Przykładowe dane\n",
    "train_data = train.drop('class', axis=1)\n",
    "train_target = train['class']\n",
    "test_data = t.drop('class', axis=1)\n",
    "test_target = t['class']\n",
    "\n",
    "# Zakodowanie klas za pomocą OneHotEncoder\n",
    "#encoder = OneHotEncoder(sparse=False)\n",
    "#train_target_encoded = encoder.fit_transform(train[['class']])\n",
    "#test_target_encoded = encoder.transform(t[['class']])\n",
    "\n",
    "# Ocena modelu\n",
    "evaluate_decisiontree_model(train_data, train_target, test_data, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a67525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bea5ecac",
   "metadata": {},
   "source": [
    "#### wnioski:\n",
    "\n",
    "1) najwyższa dokładność ogólna: knn, randomForest, gradient boosting ~ 0.96\n",
    "\n",
    "\n",
    "2) najwyższa dokładność:\n",
    "\n",
    "\n",
    "        dla Star: randomForest, gradient boosting ~ 0.98\n",
    "        \n",
    "        dla Galaxy: knn ~ 0.97\n",
    "        \n",
    "        dla Quasar: knn, gradient boosting ~ 0.96\n",
    "        \n",
    "        \n",
    "3) najwyższy średni auc: gradient, boosting, xboost, randomForest  ~ 0.99\n",
    "\n",
    "\n",
    "4) najwyższy auc:\n",
    "\n",
    "        dla Star: wszystkie oprócz Markowa i DecisionTreeClassifier ~ 0.99\n",
    "        \n",
    "        dla Galaxy: wszystkie oprócz Markowa i DecisionTreeClassifier ~ 0.99\n",
    "        \n",
    "        dla Quasar: xboost, gradient boosting ~ 0.99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe5f07",
   "metadata": {},
   "source": [
    "najsłabiej sobie radzi Model Markova\n",
    "\n",
    "Decision Tree Classifier bardzo słabo przewiduję klasę STAR, dla każdego innego modelu predykcyjność STAR jest najwyższa, często bliska 100 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69479418",
   "metadata": {},
   "source": [
    "### 3) Strojenie hiperparametrów dla wybranych modeli, wybór najlepszego"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724de8b9",
   "metadata": {},
   "source": [
    "#### Do kolejnej części wybrano te modele, które osiągnęły najlepsze wyniki z standardowymi, niezmienionymi parametrami. Są to:\n",
    "\n",
    "1) Gradient Boosting\n",
    "\n",
    "2) Random Forest Classifier\n",
    "\n",
    "3) KNeighbours Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92ae94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
